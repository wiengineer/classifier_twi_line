{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merging, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes 5\n",
      "['facebook', 'line', 'tiktok', 'twitter', 'twitter_t']\n"
     ]
    }
   ],
   "source": [
    "#フォルダ名をクラス名にする\n",
    "path = \"./sns/train\"\n",
    "folders = os.listdir(path)\n",
    "classes = [f for f in folders if os.path.isdir(os.path.join(path, f))]\n",
    "n_classes = len(classes)\n",
    "print(\"n_classes\", n_classes)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "195\n",
      "<class 'list'>\n",
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#画像の読み込みとフォルダ番号の答え\n",
    "X =[]\n",
    "y=[]\n",
    "for label, class_name in enumerate(classes):\n",
    "    files= glob(\"./sns/train/\" + class_name+\"/*.*\")\n",
    "    for file in files:\n",
    "        img=cv2.imread(file, 0)\n",
    "        img = cv2.resize(img, dsize=(224,224))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndarray化\n",
    "X_ = np.array(X)\n",
    "X_ = X_.astype(\"float32\")\n",
    "X_train = X_/255.0\n",
    "y_ = np.array(y)\n",
    "y_train = np_utils.to_categorical(y_,n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'facebook', '1': 'line', '2': 'tiktk', '3': 'twitter', '4': 'twitter_t'}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = {\"0\":\"facebook\", \"1\":\"line\", \"2\":\"tiktk\",\"3\":\"twitter\",\"4\":\"twitter_t\"}\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "X_test =[]\n",
    "y_test=[]\n",
    "for label, class_name in enumerate(classes):\n",
    "    files= glob(\"./sns/validation/\" + class_name+\"/*.*\")\n",
    "    for file in files:\n",
    "        img = cv2.imread(file,0)\n",
    "        img = cv2.resize(img, dsize=(224,224))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        X_test.append(img)\n",
    "        y_test.append(label)\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_test = X_test/255\n",
    "y_test = np.array(y_test)\n",
    "y_test = np_utils.to_categorical(y_test,n_classes)\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 224, 224, 3)\n",
      "(195, 5)\n",
      "(147, 224, 224, 3)\n",
      "(147, 5)\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "base_model = VGG16(weights=\"imagenet\", input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#後付\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(n_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"結合\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# layers =  20\n"
     ]
    }
   ],
   "source": [
    "#学習させない層\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "print('# layers = ', len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 5)                 125445    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,840,133\n",
      "Trainable params: 7,204,869\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [186], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:956\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    954\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m--> 956\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    958\u001b[0m   \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 37ms/step - loss: 1.0661 - accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#クラス名の保存\n",
    "pickle.dump(classes, open(\"classes.sav\",\"wb\"))\n",
    "#モデルの保存\n",
    "model.save(\"./cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./sns/testyou\\\\f3.jpg'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [image for image in glob(\"./sns/testyou/*.*\")]\n",
    "images[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t32.jpg'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [re.search(r\"\\\\(.*)\",number).group(1) for number in images]\n",
    "numbers[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "numbers = []\n",
    "for image in images:\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.resize(img, dsize=(224,224))\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.0\n",
    "    img = img[None, ...]\n",
    "    results.append(model.predict(img))\n",
    "    numbers.append(re.search(r\"u\\\\(.*.jpg)\",image).group(1))\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "#1枚テスト\n",
    "img = cv2.imread(\"./sns/testyou/tk50.jpg\")\n",
    "img = cv2.resize(img, dsize=(224,224))\n",
    "img = img.astype('float32')\n",
    "img /= 255.0\n",
    "img = img[None, ...]\n",
    "result = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0., 100.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "result * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#予測収納\n",
    "answers = []\n",
    "for result in results:\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    a = result * 100\n",
    "    answers.append(a)\n",
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1.jpg facebook\n",
      "f10.jpg facebook\n",
      "f2.jpg facebook\n",
      "f3.jpg facebook\n",
      "f4.jpg facebook\n",
      "f5.jpg facebook\n",
      "f6.jpg facebook\n",
      "f7.jpg facebook\n",
      "f8.jpg facebook\n",
      "f9.jpg facebook\n",
      "l.jpg line\n",
      "l11.jpg line\n",
      "l13.jpg line\n",
      "l14.jpg line\n",
      "l15.jpg line\n",
      "l16.jpg line\n",
      "l17.jpg line\n",
      "l19.jpg line\n",
      "l20.jpg line\n",
      "l21.jpg line\n",
      "l22.jpg line\n",
      "l23.jpg line\n",
      "l24.jpg line\n",
      "l25.jpg line\n",
      "l26.jpg line\n",
      "l27.jpg line\n",
      "l28.jpg line\n",
      "l29.jpg line\n",
      "l30.jpg line\n",
      "lk18.jpg line\n",
      "t.jpg twitter\n",
      "t0.jpg twitter\n",
      "t31.jpg facebook\n",
      "t32.jpg facebook\n",
      "t33.jpg facebook\n",
      "t34.jpg facebook\n",
      "t35.jpg twitter\n",
      "t36.jpg twitter\n",
      "t37.jpg twitter\n",
      "t38.jpg twitter\n",
      "t39.jpg twitter\n",
      "t40.jpg twitter\n",
      "t41.jpg twitter\n",
      "t42.jpg twitter\n",
      "t43.jpg facebook\n",
      "t44.jpg facebook\n",
      "t45.jpg twitter\n",
      "t46.jpg twitter\n",
      "t57.jpg twitter\n",
      "t58.jpg twitter\n",
      "tk47.jpg tiktk\n",
      "tk48.jpg tiktk\n",
      "tk49.jpg tiktk\n",
      "tk50.jpg tiktk\n",
      "tk52.jpg tiktk\n",
      "tk53.jpg tiktk\n",
      "tk54.jpg tiktk\n",
      "tk55.jpg tiktk\n",
      "tk56.jpg tiktk\n"
     ]
    }
   ],
   "source": [
    "for a,name in zip(answers, numbers):\n",
    "    k = a.argmax()\n",
    "    # print(name,k)\n",
    "    print(name, answer[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiktk'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = result.argmax()\n",
    "answer[str(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f0c07f233c9fa4c5b7b6dc7c1d99c0c617bce55c9a22566408c30b7d3d16372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
